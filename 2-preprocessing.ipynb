{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "Dealing with windowing, flagging AF windows, and exploring 'Pause' periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T15:57:40.841646Z",
     "start_time": "2021-02-12T15:57:39.931652Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T15:23:39.123736Z",
     "start_time": "2021-02-12T15:20:03.305361Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join('Data', 'combined_series.csv')\n",
    "\n",
    "df = pd.read_csv(filepath, parse_dates=['time'],\n",
    "                 date_parser= lambda x: pd.to_datetime(x, format='%H:%M:%S'),\n",
    "                 dtype={\n",
    "                    'interval':'uint16',\n",
    "                    'file_num':'uint16',\n",
    "                    'row_num':'uint32',\n",
    "                    'annotation':'object'\n",
    "                 }\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate number of 'Pause' periods in each 30-beat segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T15:23:41.212334Z",
     "start_time": "2021-02-12T15:23:39.126735Z"
    }
   },
   "outputs": [],
   "source": [
    "df['pause_threshold'] = (df['interval']>3000)\n",
    "# Replace the interval values for pauses with missing values, so that they do not get used in calculating summary statistics.\n",
    "df['interval'] = np.where(df['pause_threshold'], None, df['interval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T15:23:41.221260Z",
     "start_time": "2021-02-12T15:23:41.214230Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 1. Filter to records exceeding the pause threshold, 2. Count the number of these per 30-beat segment in each file.\n",
    "# pause_counts = df[df['pause_threshold']].groupby(by=['file_num', df['row_num']//30]).size() \n",
    "# pause_counts.hist(bins=30)   # Plot a histogram. Min is 1 and max is 30.\n",
    "# plt.title(\"# of pause periods per 30-beat segment\", size=14)\n",
    "# plt.xlabel(\"# of pause periods\")\n",
    "# plt.ylabel(\"# of segments\")\n",
    "\n",
    "# # Count the total number of 30-beat segments across files to compare the % with Pauses.\n",
    "# index_counts = df.groupby(by=['file_num', df['row_num']//30]).size()\n",
    "# print(\"{0:.1f}% of 30-beat segments contain at least one pause\".format(100*len(pause_counts)/len(index_counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find and tag all AF periods.\n",
    "Primarily, this means detecting START AF in the annotation field and labelling all beats from that point until END AF appears.\n",
    "If no END AF appears, then AF is present from START AF until the end of the file. Similarly, if END AF is written but no START AF then AF is present from the start of the file until END AF.\n",
    "There are a small number of variations of these annotations which should be captured. E.g. in one file, the start flag is \"AF START\", and the end flag is written in various files as \"AF END\", \"EN AF\", \"STOP AF\", and \"EINDE EPISODE AF\".\n",
    "- The condition to detect the start flag should be the presence of 'start' and 'af' in the annotation, regardless of order.\n",
    "- The condition to detect the stop flag should be the presence of 'af' and ('end' or 'en' or 'stop' or 'einde episode') \n",
    "\n",
    "Method: \n",
    "1. Create a new column with a simplified 'start' / 'end' (encoded as integers 1 and 2).\n",
    "2. Check the minimum non-NA value in this column for each file. If it is 'end' then place a 'start' in the first row for that file.\n",
    "3. Fill forward the values in the column.\n",
    "4. Replace the 'end's (2s) and NAs with 0 (AF beats will be represented by 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a new column with a simplified 'start' / 'end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T15:23:41.237185Z",
     "start_time": "2021-02-12T15:23:41.223182Z"
    }
   },
   "outputs": [],
   "source": [
    "def simplify_start_end(col):\n",
    "    return np.select( \n",
    "    [\n",
    "        pd.isnull(col),                                 # If there is no recorded annotation.\n",
    "        ~col.str.contains('af',case=False,na=False),  # If there is no 'af' in the annotation then return None.\n",
    "        col.str.contains('start',case=False,na=False), # Condition for start af\n",
    "        col.str.contains('end|(en af)|stop|(einde episode)', case=False,na=False)  # Condition for end af\n",
    "    ], \n",
    "    [\n",
    "        None,\n",
    "        None,\n",
    "        1,      # Input a 1 for 'start'\n",
    "        2       # Input a 2 for 'end'   - use integers rather than strings to optimise for memory usage.\n",
    "    ], \n",
    "    default=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T15:24:20.702908Z",
     "start_time": "2021-02-12T15:23:41.240109Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ricky\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['af_flag'] = simplify_start_end(df['annotation'])\n",
    "\n",
    "# Get rid of the annotation string column to free up memory.\n",
    "del df['annotation']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check the minimum non-NA value in this column for each file. If it is 'end' (2) then place a 'start' (1) in the first row for that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T15:24:30.982418Z",
     "start_time": "2021-02-12T15:24:20.704816Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the first non-null flag for each file.\n",
    "first_flag = df.groupby('file_num', as_index=False)[['file_num','af_flag']].first()\n",
    "# Extract the file numbers for which the first flag is 'end' (encoded as 2)\n",
    "files_with_end_first = first_flag[first_flag['af_flag']==2]['file_num']\n",
    "# Get the rows of the original dataframe that correspond to the first rows of the above files.\n",
    "df_files_with_end_first = df[(df['file_num'].isin(files_with_end_first.values)) & (df['row_num']==0)]['file_num']\n",
    "# Extract the indexes for these rows (corresponding to the indexes of the original df)\n",
    "idx = df_files_with_end_first.index\n",
    "# Insert 'start' (encoded as 1) to the af_flag column on these rows.\n",
    "df.loc[df.index.isin(idx), 'af_flag'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T17:19:28.213490Z",
     "start_time": "2021-02-10T17:19:28.135567Z"
    }
   },
   "source": [
    "3. Fill forward the values in the column.\n",
    "4. Replace the 'end's (2s) and NAs with 0 (AF beats will be represented by 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T15:24:44.896805Z",
     "start_time": "2021-02-12T15:24:30.984331Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill forward the AF flag values. So 1 will be filled forward from the start to the end of the AF episode. \n",
    "# The 'end' (encoded as 2) will also be filled forward, but these will all be replaced in the next step.\n",
    "df['af_flag'] = df['af_flag'].fillna(df.groupby('file_num')['af_flag'].ffill())\n",
    "# Replace any 2 with a 0, and replace any missing values with 0.\n",
    "df['af_flag'] = df['af_flag'].replace(2, 0).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Windowing\n",
    "Create windows of the beats within which we will calculate summary statistics and try to predict if an AF episode is captured by the window (segment).\n",
    "\n",
    "Create segments of 30 beats, and overlap each window by 50% so that we can capture AF episodes earlier and we ensure we capture as many AF episodes as possible.\n",
    "\n",
    "Tolerate up to 3 pause periods in middle of 30-beat segment but don't use in calculating summary statistics. Î”RR should be Null for those intervals. 3 is chosen based on the distribution of pause periods in segments, this will allow us to capture the vast majority of valid segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T15:25:24.221995Z",
     "start_time": "2021-02-12T15:24:44.899725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the windows based on taking every 30 values of the row number.\n",
    "df['window_1'] = df['row_num']//30\n",
    "# Create the second and third windows with a 10 & 20 beat offset, respectively. (i.e overlaps of 67%)\n",
    "df['window_2'] = [(row-10)//30 if row>9 else None for row in df['row_num']]\n",
    "df['window_3'] = [(row-20)//30 if row>19 else None for row in df['row_num']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write processed data to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T15:44:02.893379Z",
     "start_time": "2021-02-12T15:38:23.582487Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv(os.path.join('Data', 'data_window_mapping.csv'), index=False, na_rep='', chunksize=100000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "340.667px",
    "left": "584px",
    "right": "20px",
    "top": "119px",
    "width": "606px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
